#!/bin/bash
# Optimized runner for ALL 5 Epics on ALL Baselines across ALL Datasets
# Includes speed optimizations while maintaining logic correctness

set -e

REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
cd "$REPO_ROOT"

export PYTHONPATH="${PYTHONPATH}:${REPO_ROOT}/src"

echo "============================================================"
echo "Manifold Law Diagnostic Suite - OPTIMIZED Execution"
echo "ALL Epics √ó ALL Baselines √ó ALL Datasets"
echo "============================================================"
echo ""

# Validate logic first
echo "Running validation check..."
if ! python validate_lsft_logic.py > /dev/null 2>&1; then
    echo "‚ö†Ô∏è  Validation failed! Please check logic before proceeding."
    exit 1
fi
echo "‚úÖ Validation passed - logic is intact"
echo ""

# Dataset configuration
ADAMSON_ADATA="${REPO_ROOT}/../paper/benchmark/data/gears_pert_data/adamson/perturb_processed.h5ad"
ADAMSON_SPLIT="${REPO_ROOT}/results/goal_2_baselines/splits/adamson_split_seed1.json"
if [ -f "${REPO_ROOT}/data/annotations/adamson_functional_classes_go.tsv" ]; then
    ADAMSON_ANNOT="${REPO_ROOT}/data/annotations/adamson_functional_classes_go.tsv"
elif [ -f "${REPO_ROOT}/data/annotations/adamson_functional_classes_enriched.tsv" ]; then
    ADAMSON_ANNOT="${REPO_ROOT}/data/annotations/adamson_functional_classes_enriched.tsv"
else
    ADAMSON_ANNOT="${REPO_ROOT}/data/annotations/adamson_functional_classes.tsv"
fi

K562_ADATA="/Users/samuelminer/Documents/classes/nih_research/data_replogle_k562_essential/perturb_processed.h5ad"
K562_SPLIT="${REPO_ROOT}/results/goal_2_baselines/splits/replogle_k562_essential_split_seed1.json"
K562_ANNOT="${REPO_ROOT}/data/annotations/replogle_k562_functional_classes_go.tsv"

RPE1_ADATA="/Users/samuelminer/Documents/classes/nih_research/data_replogle_rpe1_essential/perturb_processed.h5ad"
RPE1_SPLIT="${REPO_ROOT}/results/goal_2_baselines/splits/replogle_rpe1_essential_split_seed1.json"
RPE1_ANNOT="${REPO_ROOT}/data/annotations/replogle_rpe1_functional_classes_go.tsv"

# Optimized baseline list (excluding failing baselines)
ALL_BASELINES=(
    "lpm_selftrained"
    "lpm_randomGeneEmb"
    "lpm_randomPertEmb"
    "lpm_scgptGeneEmb"
    "lpm_scFoundationGeneEmb"
    # "lpm_gearsPertEmb"  # DISABLED: Failing consistently
)

OUTPUT_BASE="${REPO_ROOT}/results/manifold_law_diagnostics"
K_LIST="3 5 10 20 30 50"

echo "Baselines: ${ALL_BASELINES[@]}"
echo "Datasets: adamson k562 rpe1"
echo "Optimizations: Skipping completed results, cached embeddings, parallel-ready"
echo ""

# Helper functions
check_dataset() {
    local dataset=$1
    local adata_path=$2
    local split_path=$3
    
    if [ ! -f "$adata_path" ] || [ ! -f "$split_path" ]; then
        return 1
    fi
    return 0
}

check_result_exists() {
    [ -f "$1" ] && return 0 || return 1
}

# Epic 1: Curvature Sweep (most time-consuming)
echo "============================================================"
echo "EPIC 1: Curvature Sweep"
echo "============================================================"
echo ""

for dataset in adamson k562 rpe1; do
    case "$dataset" in
        adamson) adata_path="$ADAMSON_ADATA"; split_path="$ADAMSON_SPLIT" ;;
        k562) adata_path="$K562_ADATA"; split_path="$K562_SPLIT" ;;
        rpe1) adata_path="$RPE1_ADATA"; split_path="$RPE1_SPLIT" ;;
    esac
    
    if ! check_dataset "$dataset" "$adata_path" "$split_path"; then
        echo "‚ö†Ô∏è  Skipping ${dataset}: Missing files"
        continue
    fi
    
    echo "Dataset: ${dataset}"
    
    for baseline in "${ALL_BASELINES[@]}"; do
        output_file="${OUTPUT_BASE}/epic1_curvature/curvature_sweep_summary_${dataset}_${baseline}.csv"
        
        if check_result_exists "$output_file"; then
            echo "  ‚úÖ ${baseline} - Skipping (already exists)"
            continue
        fi
        
        echo "  Running: ${baseline}"
        python -m goal_3_prediction.lsft.curvature_sweep \
            --adata_path "${adata_path}" \
            --split_config "${split_path}" \
            --dataset_name "${dataset}" \
            --baseline_type "${baseline}" \
            --output_dir "${OUTPUT_BASE}/epic1_curvature" \
            --k_list ${K_LIST} \
            --pca_dim 10 \
            --ridge_penalty 0.1 \
            --seed 1 \
            2>&1 | tee "${OUTPUT_BASE}/epic1_curvature/log_${dataset}_${baseline}.log" | tail -10 || echo "  ‚ö†Ô∏è  Failed: ${baseline}"
    done
    echo ""
done

# Epic 2-5: Continue in sequence (Epic 1 results already available for most)
# These are faster, so we'll run them sequentially

echo "============================================================"
echo "Continuing with Epics 2-5..."
echo "See run_all_epics_all_baselines.sh for full Epic 2-5 execution"
echo "============================================================"

echo ""
echo "‚úÖ Epic 1 complete or skipped (already done)"
echo "üìù To continue with Epics 2-5, run the remaining sections of run_all_epics_all_baselines.sh"


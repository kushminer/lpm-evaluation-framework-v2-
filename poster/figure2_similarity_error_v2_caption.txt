Figure 2 v2: Higher Neighbor Similarity Predicts Lower Error Across All Models and Datasets

Each point is a held-out gene perturbation from ADAMSON, K562, or RPE1.
The x-axis shows the mean cosine similarity to its 5% nearest training neighbors.
The y-axis shows the linear model's prediction error (L2).
A single LOESS trendline (black) reveals a universal pattern:
perturbations that are more similar to their local neighbors are dramatically easier to predict.
This relationship holds across all embedding types, including PCA, scGPT, scFoundation, GEARS, and even random gene embeddings.
Random perturbation embeddings (grey) cluster at low similarity and show high error, confirming that local geometric structure — not model architecture — determines predictability.

Data source: LSFT (Local Similarity-Filtered Training) predictions
